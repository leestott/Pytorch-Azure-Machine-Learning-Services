{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Dog breed classification using Pytorch Estimators on Azure Machine Learning service\n\nHave you ever seen a dog and not been able to tell the breed? Some dogs look so similar, that it can be nearly impossible to tell. For instance these are a few breeds that are difficult to tell apart:\n\n#### Alaskan Malamutes vs Siberian Huskies\n![Image of Alaskan Malamute vs Siberian Husky](http://cdn.akc.org/content/article-body-image/malamutehusky.jpg)\n\n#### Whippet vs Italian Greyhound \n![Image of Whippet vs Italian Greyhound](http://cdn.akc.org/content/article-body-image/whippetitalian.jpg)\n\nThere are sites like http://what-dog.net, which use Microsoft Cognitive Services to be able to make this easier. \n\nIn this tutorial, you will learn how to train a Pytorch image classification model using transfer learning with the Azure Machine Learning service. The Azure Machine Learning python SDK's [PyTorch estimator](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-pytorch) enables you to easily submit PyTorch training jobs for both single-node and distributed runs on Azure compute. The model is trained to classify dog breeds using the [Stanford Dog dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) and it is based on a pretrained ResNet18 model. This ResNet18 model has been built using images and annotation from ImageNet. The Stanford Dog dataset contains 120 classes (i.e. dog breeds), to save time however, for most of the tutorial, we will only use a subset of this dataset which includes only 10 dog breeds."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What is Azure Machine Learning service?\nAzure Machine Learning service is a cloud service that you can use to develop and deploy machine learning models. Using Azure Machine Learning service, you can track your models as you build, train, deploy, and manage them, all at the broad scale that the cloud provides.\n![](aml-overview.png)\n\n\n## How can we use it for training image classification models?\nTraining machine learning models, particularly deep neural networks, is often a time- and compute-intensive task. Once you've finished writing your training script and running on a small subset of data on your local machine, you will likely want to scale up your workload.\n\nTo facilitate training, the Azure Machine Learning Python SDK provides a high-level abstraction, the estimator class, which allows users to easily train their models in the Azure ecosystem. You can create and use an Estimator object to submit any training code you want to run on remote compute, whether it's a single-node run or distributed training across a GPU cluster. For PyTorch and TensorFlow jobs, Azure Machine Learning also provides respective PyTorch and TensorFlow estimators to simplify using these frameworks.\n\n### Steps to train with a Pytorch Estimator:\nIn this tutorial, we will:\n- Connect to an Azure Machine Learning service Workspace \n- Create a remote compute target\n- Upload your training data (Optional)\n- Create your training script\n- Create an Estimator object\n- Submit your training job"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Understanding Azure Machine Learning [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) is while it is being created.\n![](aml-workspace.png)\n\n\n## Create a remote compute target\nFor this tutorial, we will create an AML Compute cluster with a NC6s_v3, V100 GPU machines, created to use as the [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to execute your training script on. \n"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Check core SDK version number\nimport azureml.core\n\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "No module named 'azureml.core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2e9d4de75a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check core SDK version number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SDK version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named 'azureml.core'"
          ]
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create workspace\n\nIn the next step, you will create your own Workspace to use in this tutorial.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prerequisites\nMake sure you have access to an Azure subscription."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Specify subscription parameters\nsubscription_id='EnterWorkSpaceID'\nworkspace_name='EnterWorkSpaceName'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\nlocation='westeurope'\nresource_group='azureml-webinar'\n\nws = Workspace.create(name = workspace_name,\n                      subscription_id = subscription_id,\n                      resource_group = resource_group, \n                      location = location,\n                      exist_ok = True)\n\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "No module named 'azureml.core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b775a7e88ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'westeurope'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresource_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'azureml-webinar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named 'azureml.core'"
          ]
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n**Creation of the cluster takes approximately 5 minutes, but we will not wait for it to complete** \n\nIf the cluster is already in your workspace this code will skip the cluster creation process. Note that the code is not waiting for completion of the cluster creation. If needed you can call `compute_target.wait_for_completion(show_output=True)`, which will block you notebook until the compute target is provisioned"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AmlCompute, ComputeTarget\n\n# choose a name for your cluster\ncluster_name = \"v100cluster1\"\n\ntry:\n    compute_target = ws.compute_targets[cluster_name]\n    print('Found existing compute target.')\nexcept KeyError:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6s_v3', \n                                                           idle_seconds_before_scaledown=1800,\n                                                           min_nodes=1, \n                                                           max_nodes=4)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n    compute_target.wait_for_completion(show_output=True)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Use existing compute target\ncluster_name = \"v100cluster2\"\n\ncompute_target = ws.compute_targets[cluster_name]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# At any time you can check the status of the compute target\nprint(compute_target.status.serialize())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Upload the Data\nThe dog-breeds images dataset is available on github repository. Here, we'll copy the data to the default datastore of the workspace."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nimport urllib\nfrom zipfile import ZipFile\n\n# download data\ndownload_url = 'https://github.com/heatherbshapiro/pycon-canada/raw/master/breeds-10.zip'\ndata_file = './breeds-10.zip'\nurllib.request.urlretrieve(download_url, filename=data_file)\n\n# extract files\nwith ZipFile(data_file, 'r') as zip:\n    print('extracting files...')\n    zip.extractall()\n    print('done')\n    \n# delete zip file\nos.remove(data_file)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ds = ws.get_default_datastore()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ds.upload(src_dir='./breeds-10', target_path='breeds-10')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's get a reference to the path on the datastore with the training data. We can do so using the `path` method. In the next section, we can then pass this reference to our training script's `--data_dir` argument. We will start with the 10 classes dataset."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "path_on_datastore = 'breeds-10'\nds_data = ds.path(path_on_datastore)\nprint(ds_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Prepare training script\nNow you will need to create your training script. In this tutorial, the training script is already provided for you at `pytorch_train.py`. In practice, you should be able to take any custom training script as is and run it with AML without having to modify your code.\n\nHowever, if you would like to use AML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of AML code inside your training script. \n\nIn `pytorch_train.py`, we will log some metrics to our AML run. To do so, we will access the AML run object within the script:\n```Python\nfrom azureml.core.run import Run\nrun = Run.get_context()\n```\nFurther within `pytorch_train.py`, we log the learning rate and momentum parameters, the best validation accuracy the model achieves, and the number of classes in the model:\n```Python\nrun.log('lr', np.float(learning_rate))\nrun.log('momentum', np.float(momentum))\nrun.log('num_classes', num_classes)\n\nrun.log('best_val_acc', np.float(best_acc))\n```\n\nIf you downloaded the data, you can start to train the model locally (note that it will take long if you don't have a GPU -- 21 min. on a Core i7 CPU).\n\n**This step requires Pytorch to be installed locally -- find instructions [here](https://pytorch.org/#pip-install-pytorch)**\n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "!mkdir outputs\n!python pytorch_train.py --data_dir breeds-10 --num_epochs 10 --output_dir outputs ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train model on the remote compute\nNow that you have your data and training script prepared, you are ready to train on your remote compute cluster. You can take advantage of Azure compute to leverage GPUs to cut down your training time. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create an experiment\nCreate an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this transfer learning PyTorch tutorial. "
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\n\nexperiment_name = 'pytorch-dogs' \nexperiment = Experiment(ws, name=experiment_name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a PyTorch estimator\nThe AML SDK's PyTorch estimator enables you to easily submit PyTorch training jobs for both single-node and distributed runs. For more information on the PyTorch estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch). The following code will define a single-node PyTorch job."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import PyTorch\n\nscript_params = {\n    '--data_dir': ds_data.as_mount(),\n    '--num_epochs': 10,\n    '--output_dir': './outputs',\n    '--log_dir': './logs',\n    '--mode': 'fine_tune'\n}\n\nestimator10 = PyTorch(source_directory='.', \n                    script_params=script_params,\n                    compute_target=compute_target, \n                    entry_script='pytorch_train.py',\n                    pip_packages=['tensorboardX'],\n                    use_gpu=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`. Please note the following:\n- We passed our training data reference `ds_data` to our script's `--data_dir` argument. This will 1) mount our datastore on the remote compute and 2) provide the path to the training data `breeds` on our datastore.\n- We specified the output directory as `./outputs`. The `outputs` directory is specially treated by AML in that all the content in this directory gets uploaded to your workspace as part of your run history. The files written to this directory are therefore accessible even once your remote run is over. In this tutorial, we will save our trained model to this output directory.\n\nTo leverage the Azure VM's GPU for training, we set `use_gpu=True`."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Submit job\nRun your experiment by submitting your estimator object. Note that this call is asynchronous."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "run10 = experiment.submit(estimator10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Monitor your run\nYou can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run10).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### What happens during a run?\nIf you are running this for the first time, the compute target will need to pull the docker image, which will take about 2 minutes. This gives us the time to go over how a **Run** is executed in Azure Machine Learning. \n\nNote: had we not created the workspace with an existing ACR, we would have also had to wait for the image creation to be performed -- that takes and extra 10-20 minutes for big GPU images like this one. This is a one-time cost for a given python configuration, and subsequent runs will then be faster. We are working on ways to make this image creation faster.\n\n![](aml-run.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using Tensorboard\nTensorboard is a popular Deep Learning Training visualization tool. It is part of TensorFlow framework, but can be used from PyTorch as well by using TensorboadX python package. TensorboardX allows PyTorch to write metrics and log information in Tensorboard format.\n\nIn `pytorch_train.py`, we will log metrics to \"magical\" `logs` directory. The content of this special directory is automatically streamed by Azue ML service. The logging into Tensorboard event format is performed by SummaryWriter object:\n```Python\nfrom tensorboardX import SummaryWriter\nwriter = SummaryWriter(f'./logs/{run.id}')\n```\nWithin the script we write more detailed mini-batch loss and accuracy, as well as epoch level accuracy to Tensorboard:\n```Python\nwriter.add_scalar(f'{phase}/Loss', loss.item(), niter)\nwriter.add_scalar(f'{phase}/Epoch_accuracy', epoch_acc, (epoch+1) * len(dataloaders[phase]))\n```\nFinally, to ensure that TensorboardX python package is installed in Python environment during the training run, we add it using pip_packages parameter of the Estimator object:\n```Python\nestimator = PyTorch(...\n                    pip_packages=['tensorboardX']\n                    ...)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Installing and launching Tensorboard\nAzure ML SDK provides built-in integration with Tensorboard in package `azureml-contrib-tensorboard`, installed as part of the contrib extras package in prerequisites. In addition, you will need to pip install tensorboard, which we also did as part of the prerequisites.\n\nWhile the run is in progress (or after it has completed), we just need to start Tensorboard with the run as its target, and it will begin streaming logs."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.contrib.tensorboard import Tensorboard\n\n# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\ntb = Tensorboard([run10])\n\n# If successful, start() returns a string with the URI of the instance.\ntb.start()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Stop Tensorboard\n\nWhen you're done, make sure to call the `stop()` method of the Tensorboard object, or it will stay running even after your job completes."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "tb.stop()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Distributed training\n\nNow that the setup is working, we can go to the full dataset with 120 classes. We just need to point to a different path on the datastore. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "full_dataset = ds.path('breeds')\nprint(full_dataset)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## AML Compute\nfrom azureml.train.dnn import PyTorch\n\nscript_params = {\n    '--data_dir': full_dataset.as_mount(),\n    '--num_epochs': 25,\n    '--output_dir': './outputs',\n    '--log_dir': './logs',\n    '--mode': 'fine_tune'\n}\n\nestimator120 = PyTorch(source_directory='.', \n                        script_params=script_params,\n                        compute_target=compute_target, \n                        entry_script='pytorch_train.py',\n                        pip_packages=['tensorboardX'],\n                        node_count=1,\n                        use_gpu=True)\n\nrun120 = experiment.submit(estimator120)\n\nfrom azureml.widgets import RunDetails\nRunDetails(run120).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But now training takes very long (> 1 hour), so let's see if we can run this job on multiple GPUs to cut down on training time."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# first let's cancel the above job\nrun120.cancel()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Running the model on multiple nodes is simple (in this case using Horovod MPI-based algorithm running on 4 nodes)"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## AML Compute\nfrom azureml.train.dnn import PyTorch\n\nscript_params = {\n    '--data_dir': full_dataset.as_mount(),\n    '--num_epochs': 25,\n    '--output_dir': './outputs',\n    '--log_dir': './logs',\n    '--mode': 'fine_tune'\n}\n\nestimator120 = PyTorch(source_directory='.', \n                        script_params=script_params,\n                        compute_target=compute_target, \n                        pip_packages=['tensorboardX'],\n                        entry_script='pytorch_train_horovod.py',\n                        node_count=4,\n                        distributed_backend='mpi',\n                        use_gpu=True)\n\nrun120 = experiment.submit(estimator120)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run120).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.contrib.tensorboard import Tensorboard\n\n# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\ntb = Tensorboard([run120])\n\n# If successful, start() returns a string with the URI of the instance.\ntb.start()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "tb.stop()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Training on 4 nodes completes in about 25 minutes and achieves 81% accuracy, which is similar to accuracy produced by single node training. This is great improvement of training time."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hyperparameter Tuning\n Now that you have trained an initial model, you can tune the hyperparameters of this model to optimize model performance. Azure ML allows you to automate this tuning, in an efficient manner via early termination of poorly performing runs.\n\nYou can configure your Hyperparamter Tuning experiment by specifying the following info -\n- Define the hyparparameter space - specify ranges, distribution and sampling\n- Early Termination policy\n- Optimization metric\n- Resource / Compute budget\n- Desired concurrency\n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import PyTorch\n\nscript_params = {\n    '--data_dir': ds_data.as_mount(),\n    '--num_epochs': 40,\n    '--output_dir': './outputs',\n    '--log_dir': './logs',\n    '--mode': 'fine_tune'\n}\n\nestimator10_40 = PyTorch(source_directory='.', \n                    script_params=script_params,\n                    compute_target=compute_target, \n                    entry_script='pytorch_train.py',\n                    pip_packages=['tensorboardX'],\n                    use_gpu=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.train.hyperdrive import *\n\nps = RandomParameterSampling(\n    {\n        '--momentum': uniform(0.6,0.99),\n        '--learning_rate': loguniform(-6, -3)\n    }\n)\n\npolicy = BanditPolicy(evaluation_interval=2, slack_factor=0.2)\n\n\nhdc = HyperDriveRunConfig(estimator=estimator10_40, \n                          hyperparameter_sampling=ps, \n                          policy=policy, \n                          primary_metric_name='best_val_acc', \n                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                          max_total_runs=50,\n                          max_concurrent_runs=4)\n\nhd_run = experiment.submit(hdc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(hd_run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "While the jobs is running, take a look at the [Hyperdrive documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive?view=azure-ml-py) to see what other options Hyperdrive offers."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# at any time, you can pull out the metrics generated so far from the runs\nhd_run.get_metrics()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Inferencing\n### Create scoring script\n\nFirst, we will create a scoring script that will be invoked by the web service call. Note that the scoring script must have two required functions:\n* `init()`: In this function, you typically load the model into a `global` object. This function is executed only once when the Docker container is started. \n* `run(input_data)`: In this function, the model is used to predict a value based on the input data. The input and output typically use JSON as serialization and deserialization format, but you are not limited to that.\n\nRefer to the scoring script `pytorch_score.py` for this tutorial. Our web service will use this file to predict the dog breed based on a 120 class model trained earlier, located in the folder `model`. We will test the scoring file locally first before you go and deploy the web service.\n\n1. Import the scoring script, so that init() and run() are accessible"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport pytorch_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "2. Call the init function -- this will load the model and the class_names from the model directory"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "pytorch_score.init()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "3. Add some helper functions:"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os, json, base64\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom PIL import Image\nimport urllib.request\nimport io, requests\n\n##Get random dog\ndef get_random_dog():\n    r = requests.get(url =\"https://dog.ceo/api/breeds/image/random\")\n    URL= r.json()['message']\n    return URL\n\ndef imgToBase64(img):\n    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n    imgio = BytesIO()\n    img.save(imgio, 'JPEG')\n    img_str = base64.b64encode(imgio.getvalue())\n    return img_str.decode('utf-8')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "4. Find an image of a dog and call the run() function"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "##Get Random Dog Image\nURL = get_random_dog()\n\nwith urllib.request.urlopen(URL) as url:\n    test_img = io.BytesIO(url.read())\n\n\nplt.imshow(Image.open(test_img))\n\nbase64Img = imgToBase64(Image.open(test_img))\n\nresult = pytorch_score.run(input_data=json.dumps({'data': base64Img}))\nprint(URL)\nprint(json.loads(result))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Register the model\nOnce the run completes, we can register the model that was created.\n\n**Please use a unique name for the model**"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\nmodel = Model.register(ws, model_name='model', model_path = 'model', description='120 Dogbreeds')\nprint(model.name, model.id, model.version, sep = '\\t')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy model as web service\nOnce you have your trained model, you can deploy the model on Azure. You can deploy your trained model as a web service on Azure Container Instances (ACI), Azure Kubernetes Service (AKS), IoT edge device, or field programmable gate arrays (FPGAs)\n\nACI is generally cheaper than AKS and can be set up in 4-6 lines of code. ACI is the perfect option for testing deployments. Later, when you're ready to use your models and web services for high-scale, production usage, you can deploy them to AKS.\n\n\nIn this tutorial, we will deploy the model as a web service in [Azure Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/) (ACI). \n\n\nFor more information on deploying models using Azure ML, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create environment file\nThen, we will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by AML. In this case, we need to specify `torch`, `torchvision`, `pillow`, and `azureml-sdk`."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%writefile myenv.yml\nname: myenv\nchannels:\n  - defaults\ndependencies:\n  - pip:\n    - torch\n    - torchvision\n    - pillow\n    - azureml-core",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Configure the container image\nNow configure the Docker image that you will use to build your ACI container."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.image import ContainerImage\n\nimage_config = ContainerImage.image_configuration(execution_script='pytorch_score.py', \n                                                  runtime='python', \n                                                  conda_file='myenv.yml',\n                                                  description='Image with dog breed model')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Configure the ACI container\nWe are almost ready to deploy. Create a deployment configuration file to specify the number of CPUs and gigabytes of RAM needed for your ACI container. While it depends on your model, the default of `1` core and `1` gigabyte of RAM is usually sufficient for many models."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=1, \n                                               tags={'data': 'dog_breeds',  'method':'transfer learning', 'framework':'pytorch'},\n                                               description='Classify dog breeds using transfer learning with PyTorch')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy the registered model\nFinally, let's deploy a web service from our registered model. First, retrieve the model from your workspace."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\n\nmodel = ws.models['model']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Then, deploy the web service using the ACI config and image config files created in the previous steps. We pass the `model` object in a list to the `models` parameter. If you would like to deploy more than one registered model, append the additional models to this list.\n\n** Please use a unique service name**"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\n\nservice_name = 'dog120'\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name=service_name,\n                                       models=[model],\n                                       image_config=image_config,\n                                       deployment_config=aciconfig,)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.state)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If your deployment fails for any reason and you need to redeploy, make sure to delete the service before you do so: `service.delete()`"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:**"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "service.get_logs()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Get the web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test the web service\nFinally, let's test our deployed web service. We will send the data as a JSON string to the web service hosted in ACI and use the SDK's `run` API to invoke the service. Here we will take an arbitrary image from online to predict on. This is the same as above, but now we are testing on our own trained model. You can use any dog image, but please remember we only trained on 10 classes."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "##Get Random Dog Image\nURL = get_random_dog()\n\nwith urllib.request.urlopen(URL) as url:\n    test_img = io.BytesIO(url.read())\n\nplt.imshow(Image.open(test_img))\n\nwith urllib.request.urlopen(URL) as url:\n    test_img = io.BytesIO(url.read())\n\nplt.imshow(Image.open(test_img))\nprint(URL)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def imgToBase64(img):\n    \"\"\"Convert pillow image to base64-encoded image\"\"\"\n    imgio = BytesIO()\n    img.save(imgio, 'JPEG')\n    img_str = base64.b64encode(imgio.getvalue())\n    return img_str.decode('utf-8')\n\nbase64Img = imgToBase64(Image.open(test_img))\n\nresult = service.run(input_data=json.dumps({'data': base64Img}))\nprint(json.loads(result))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Delete web service\nOnce you no longer need the web service, you should delete it."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}